{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8636c1c",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "df8f4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa6b13",
   "metadata": {},
   "source": [
    "Firstly, load the data. The data set is wide and long, with 8378 rows and 195 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4c0adc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 195)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dating_df = pd.read_csv(\"speed_dating_data.csv\", encoding=\"ISO-8859-1\")\n",
    "dating_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cab65e",
   "metadata": {},
   "source": [
    "### Select necessary columns\n",
    "The data set is super wide, and there are so many variables. So we went through the codebook made by the creators of this data set and selected variables we currently think would be necessary for our future analysis. Now we still have 21 columns. \n",
    "\n",
    "Certainly, we won't use all of them at once in a logistic regression model. For example, demographic information about the participants such as \"race\" and \"field\" will be mainly used in descriptive statistics for us to know about the subject population and detect sampling bias of the study rather than using them as explanatory variables in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "563653ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 21)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_list = ['iid', 'gender', 'wave', 'round', 'pid',\n",
    "               'age', 'field_cd', 'race','career_c',\n",
    "               'attr3_1','sinc3_1', 'fun3_1', 'intel3_1', 'amb3_1', \n",
    "               'dec', 'attr', 'sinc','intel', 'fun', 'amb', 'shar']\n",
    "\n",
    "dating_df = dating_df[select_list]\n",
    "dating_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfdfc63",
   "metadata": {},
   "source": [
    "### Rename columns\n",
    "\n",
    "Though we did not do any web scraping or merge data sets to get this data frame, one main effort we made was to interpret the meaning of each variable – carefully reading through the 15-paged codebook. We noticed that some of the names of the given variable names were vague. So, we decided to change them so they conveyed more straightforward information about the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5736c77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'wave', 'num_dates', 'partner_id', 'age', 'field_cd',\n",
       "       'race', 'career_c', 'rate_self_attr', 'rate_self_sinc', 'rate_self_fun',\n",
       "       'rate_self_intel', 'rate_self_amb', 'decision', 'rate_p_attr',\n",
       "       'rate_p_sinc', 'rate_p_intel', 'rate_p_fun', 'rate_p_amb',\n",
       "       'rate_p_shar'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dating_df = dating_df.rename(columns = {\"iid\":\"id\",\n",
    "                                        \"round\": \"num_dates\", \n",
    "                                        \"pid\": \"partner_id\", \n",
    "                                        \"dec\": \"decision\",\n",
    "                                        \"attr3_1\": \"rate_self_attr\", \n",
    "                                        \"sinc3_1\": \"rate_self_sinc\",\n",
    "                                        \"fun3_1\": \"rate_self_fun\",\n",
    "                                        \"intel3_1\": \"rate_self_intel\",\n",
    "                                        \"amb3_1\": \"rate_self_amb\",\n",
    "                                        \"attr\": \"rate_p_attr\",\n",
    "                                        \"sinc\": \"rate_p_sinc\",\n",
    "                                        \"fun\": \"rate_p_fun\",\n",
    "                                        \"intel\": \"rate_p_intel\",\n",
    "                                        \"amb\": \"rate_p_amb\",\n",
    "                                        \"shar\": \"rate_p_shar\"})\n",
    "dating_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb599d3",
   "metadata": {},
   "source": [
    "### Remove biased observations\n",
    "The researchers ran 21 speed dating sessions, or waves, in total. However, as they explained in their paper, they removed four sessions (waves 18-21) from the analysis \"because they involved an experimental intervention where participants were asked to bring their favorite book. These four sessions were run specifically to study how decision weights and selectivity would be affected by an intervention designed to shift subjects’ attention away from superficial physical attributes. They are omitted so that the only experimental difference across sessions is group size.\" Accordingly we also removed data for these four sessions. \n",
    "\n",
    "The researchers also said they removed another wave (#12) because they \"imposed a maximum number of acceptances\" on participants of this wave. We thought this restriction would affect participants' decisions, so we also removed this wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7076d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6412, 21)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dating_df = dating_df[~dating_df['wave'].isin([12, 18, 19, 20, 21])]\n",
    "dating_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ecfc88",
   "metadata": {},
   "source": [
    "### Deal with missing values\n",
    "We noticed there were many missing values due to how the experiment was designed and conducted. For each variable with more than 200 missing values, we re-examined whether we still thought it would be a potential good predictor in our future modeling given the fact that including it would mean fewer data points to train the model, which might make the model less robust. Finally we decided to remove the variable called \"rate_p_shar,\" which was the dater's rating of shared interests/hobbies for the datee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "602bb8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['partner_id', 10]\n",
      "['age', 73]\n",
      "['field_cd', 82]\n",
      "['race', 63]\n",
      "['career_c', 138]\n",
      "['rate_self_attr', 105]\n",
      "['rate_self_sinc', 105]\n",
      "['rate_self_fun', 105]\n",
      "['rate_self_intel', 105]\n",
      "['rate_self_amb', 105]\n",
      "['rate_p_attr', 130]\n",
      "['rate_p_sinc', 196]\n",
      "['rate_p_intel', 208]\n",
      "['rate_p_fun', 260]\n",
      "['rate_p_amb', 553]\n",
      "['rate_p_shar', 874]\n"
     ]
    }
   ],
   "source": [
    "# count NAs for each column\n",
    "for col in dating_df:\n",
    "    n = sum(pd.isna(dating_df[col]))\n",
    "    if (n > 0):\n",
    "        print([col, n])\n",
    "\n",
    "dating_df = dating_df.drop([\"rate_p_shar\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e4deb",
   "metadata": {},
   "source": [
    "Next, let's see how many rows would be left if all rows with any missing values were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3469273e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5601, 20)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dating_df = dating_df.dropna()\n",
    "dating_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de71c4bd",
   "metadata": {},
   "source": [
    "From a statistical standpoint, a sample of 5601 datapoints would be good enough for logistic regression. We would also have enough for splitting it into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb0e5e",
   "metadata": {},
   "source": [
    "### Map coded categorical variables to their corresponding values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d50e4",
   "metadata": {},
   "source": [
    "Some categorical variables were coded as integers (e.g., gender, field, race, career). This was for data storage and system performance reasons. For our purposes, we thought it would be better if these variables were also presented as the actual values so that we could visualize them more efficiently. So we did the following conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "36643b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Law' 'Political Science/International Affairs' 'Business/Econ/Finance'\n",
      " 'Engineering' 'Education, Academia' 'Social Science, Psychologist'\n",
      " 'Social Work' 'Math' 'Undergrad/undecided'\n",
      " 'Medical Science, Pharmaceuticals, and Bio Tech'\n",
      " 'History/Religion/Philosophy' 'English/Creative Writing/Journalism'\n",
      " 'Biological Sciences/Chemistry/Physics' 'Film' 'Languages'\n",
      " 'Fine Arts/Arts Administration' 'Architecture']\n",
      "['European/Caucasian-American' 'Asian/Pacific Islander/Asian-American'\n",
      " 'Other' 'Latino/Hispanic American' 'Black/African American']\n",
      "['Lawyer ' 'Creative Arts/Entertainment'\n",
      " 'International/Humanitarian Affairs' 'Academic/Research'\n",
      " 'Banking/Consulting/Finance/Marketing/Business' 'Undecided' 'Engineer'\n",
      " 'Psychologist' 'Doctor/Medicine' 'Pro sports/Athletics' 'Social Work'\n",
      " 'Real Estate' 'Other' 'Architecture' 'Politics']\n",
      "['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "field_mapping = {1:\"Law\", 2:\"Math\", 3:\"Social Science, Psychologist\", \n",
    "                4:\"Medical Science, Pharmaceuticals, and Bio Tech\", \n",
    "                5:\"Engineering\", \n",
    "                 6:\"English/Creative Writing/Journalism\", \n",
    "                7:\"History/Religion/Philosophy\", \n",
    "                 8:\"Business/Econ/Finance\", \n",
    "                9:\"Education, Academia\", \n",
    "                 10:\"Biological Sciences/Chemistry/Physics\", \n",
    "                11:\"Social Work\", 12:\"Undergrad/undecided\", \n",
    "                13:\"Political Science/International Affairs\", 14:\"Film\", \n",
    "                15:\"Fine Arts/Arts Administration\", 16:\"Languages\", \n",
    "                17:\"Architecture\", 18:\"Other\"}\n",
    "\n",
    "dating_df[\"field\"] = dating_df[\"field_cd\"].map(field_mapping)\n",
    "\n",
    "race_mapping = {1: \"Black/African American\", \n",
    "                2:\"European/Caucasian-American\", \n",
    "                3:\"Latino/Hispanic American\", \n",
    "                4:\"Asian/Pacific Islander/Asian-American\", \n",
    "                5:\"Native American\", 6:\"Other\"}\n",
    "dating_df[\"race_cd\"] = dating_df[\"race\"]\n",
    "dating_df[\"race\"] = dating_df[\"race_cd\"].map(race_mapping)\n",
    "\n",
    "career_mapping = {1:\"Lawyer \", 2:\"Academic/Research\", \n",
    "                  3:\"Psychologist\",4:\"Doctor/Medicine\",\n",
    "                  5:\"Engineer\", 6:\"Creative Arts/Entertainment\", \n",
    "                  7:\"Banking/Consulting/Finance/Marketing/Business\", \n",
    "                  8:\"Real Estate\", \n",
    "                  9:\"International/Humanitarian Affairs\", \n",
    "                  10:\"Undecided\", 11:\"Social Work\", \n",
    "                  12:\"Speech Pathology\", 13:\"Politics\", \n",
    "                  14:\"Pro sports/Athletics\", \n",
    "                  15:\"Other\", 16:\"Journalism\", 17:\"Architecture\"}\n",
    "dating_df[\"career\"] = dating_df[\"career_c\"].map(career_mapping)\n",
    "\n",
    "dating_df[\"gender_cd\"] = dating_df[\"gender\"]\n",
    "dating_df[\"gender\"] = dating_df[\"gender_cd\"].map({0:\"Female\", 1:\"Male\"})\n",
    "\n",
    "# check that they were successfully updated\n",
    "print(dating_df[\"field\"].unique())\n",
    "print(dating_df[\"race\"].unique())\n",
    "print(dating_df[\"career\"].unique())\n",
    "print(dating_df[\"gender\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3deba2a",
   "metadata": {},
   "source": [
    "### Convert data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d644d5e0",
   "metadata": {},
   "source": [
    "We also noticed some data types of the columns did not accurately reflect what they should be. For example, variables race, field, career, and gender should be of type category. And age, partner_id, and partner_age should be of type int. Other numerical variables such as rate_self_attr and rate_p_attr represent ratings on a scale of 1-10, so they should also be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "860961e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                    int64\n",
      "gender             category\n",
      "wave                  int64\n",
      "num_dates             int64\n",
      "partner_id            int64\n",
      "age                   int64\n",
      "field_cd              int64\n",
      "race               category\n",
      "career_c              int64\n",
      "rate_self_attr        int64\n",
      "rate_self_sinc        int64\n",
      "rate_self_fun         int64\n",
      "rate_self_intel       int64\n",
      "rate_self_amb         int64\n",
      "decision              int64\n",
      "rate_p_attr           int64\n",
      "rate_p_sinc           int64\n",
      "rate_p_intel          int64\n",
      "rate_p_fun            int64\n",
      "rate_p_amb            int64\n",
      "field              category\n",
      "race_cd               int64\n",
      "career             category\n",
      "gender_cd             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_types = dating_df.dtypes\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8449f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                    int64\n",
      "gender             category\n",
      "wave                  int64\n",
      "num_dates             int64\n",
      "partner_id            int64\n",
      "age                   int64\n",
      "field_cd              int64\n",
      "race               category\n",
      "career_c              int64\n",
      "rate_self_attr        int64\n",
      "rate_self_sinc        int64\n",
      "rate_self_fun         int64\n",
      "rate_self_intel       int64\n",
      "rate_self_amb         int64\n",
      "decision              int64\n",
      "rate_p_attr           int64\n",
      "rate_p_sinc           int64\n",
      "rate_p_intel          int64\n",
      "rate_p_fun            int64\n",
      "rate_p_amb            int64\n",
      "field              category\n",
      "race_cd               int64\n",
      "career             category\n",
      "gender_cd             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convert objects to categories\n",
    "temp = dating_df[[\"race\", \"field\", \"career\", \"gender\"]].astype(\"category\")\n",
    "dating_df[[\"race\", \"field\", \"career\", \"gender\"]] = temp\n",
    "# convert floats to integers\n",
    "float_columns = dating_df.select_dtypes(include=['float']).columns\n",
    "dating_df[float_columns] = dating_df[float_columns].astype(int)\n",
    "\n",
    "# check\n",
    "print(dating_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2510a11",
   "metadata": {},
   "source": [
    "### Detect inaccurate observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a7e6f",
   "metadata": {},
   "source": [
    "As mentioned above, variables such as rate_self_attr and rate_p_attr represent ratings on a scale of 1-10. It was necessary to check if this was really the case. We did not trust the data because the original dataset was not well cleaned. We better did this ourselves. And we did catch abnormal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a5698d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5585, 24)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in [\n",
    "       'rate_self_attr', 'rate_self_sinc', 'rate_self_fun', 'rate_self_intel',\n",
    "       'rate_self_amb', 'rate_p_attr', 'rate_p_sinc',\n",
    "       'rate_p_intel', 'rate_p_fun', 'rate_p_amb']:\n",
    "    dating_df = dating_df[(dating_df[col] > 0) & (dating_df[col] <= 10)]\n",
    "dating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4b293fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dating_df.to_csv(\"dating_main.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
